# Configuration file for Snakemake workflow
# Each section corresponds to a rule in the Snakemake file

# Parameters for collecting papers
rule_collect_papers:
  # Path to the configuration file for ScopusDataSource
  config_path: "pybliometrics.cfg"
  # Keywords for the paper query
  keywords: "'electrocatalyst' OR 'high entropy alloy'"
  # Start year for the paper query, or "" for no start year
  startyear: ""
  # End year for the paper query
  endyear: 2022
  # Whether to search for open access papers
  openaccess: true
  # Output path for the collected papers CSV file
  output_path: "HEA_electrocatalyst.csv"

# Configuration for pybliometrics.cfg, which will be created/updated if it doesn't exist
# Full content for pybliometrics.cfg
pybliometrics_config:
  Directories:
    AbstractRetrieval: "/pybliometrics/Scopus/abstract_retrieval"
    AffiliationRetrieval: "/pybliometrics/affiliation_retrieval"
    AffiliationSearch: "/pybliometrics/affiliation_search"
    AuthorRetrieval: "/pybliometrics/author_retrieval"
    AuthorSearch: "/pybliometrics/author_search"
    CitationOverview: "/pybliometrics/citation_overview"
    ScopusSearch: "/pybliometrics/scopus_search"
    SerialSearch: "/pybliometrics/serial_search"
    SerialTitle: "/pybliometrics/serial_title"
    PlumXMetrics: "/pybliometrics/plumx"
    SubjectClassifications: "/pybliometrics/subject_classification"

  Authentication:
    APIKey:
      - "your_api_key"
      # Add more API keys as needed

  Requests:
    Timeout: 36000
    Retries: 2

# Parameters for processing collected papers
rule_process_papers:
  # Input path for the collected papers CSV file
  input_path: "HEA_electrocatalyst.csv"
  # Output path for the processed papers CSV file
  output_path: "HEA_electrocatalyst_processed_df.csv"

# Parameters for generating word2vec model
rule_generate_word2vec:
  # Input path for the processed papers CSV file
  input_path: "HEA_electrocatalyst_processed_df.csv"
  # Output path for the generated word2vec model
  model_path: "HEA_electrocatalyst.model"
  # Training algorithm: 1 for skip-gram, 0 for CBOW
  sg: 1
  # Dimensionality of the word vectors
  vector_size: 200
  # If 1, hierarchical softmax will be used for model training
  hs: 1
  # Maximum distance between the current and predicted word within a sentence
  window: 5
  # Ignores all words with total frequency lower than this
  min_count: 1
  # Number of worker threads to train the model
  workers: 4

